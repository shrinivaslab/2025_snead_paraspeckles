{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation of Polymer Dynamics\n",
    "\n",
    "This Jupyter Notebook documents the workflow for simulating polymer dynamics using HOOMD-blue. The simulation involves creating polymers, adding them to a simulation box, running the simulation, and analyzing the results. The key steps are outlined below:\n",
    "\n",
    "1. **Import Libraries**: Import necessary libraries and modules.\n",
    "2. **Define Functions**: Define functions for creating polymers and adding them to the simulation.\n",
    "3. **Run Simulations**: Execute the simulation with specified parameters.\n",
    "4. **Analyze Data**: Analyze the simulation data to extract meaningful insights.\n",
    "5. **Plot Results**: Visualize the results using various plots.\n",
    "\n",
    "Each section of the notebook contains detailed explanations and code snippets to guide you through the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import hoomd\n",
    "import gsd\n",
    "import random\n",
    "import gsd.hoomd\n",
    "import os\n",
    "import freud\n",
    "import os\n",
    "import pickle\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "today = str(date.today())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create simulations and run with transcription dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_least_dense_area(snap,grid_size=10):\n",
    "    \"\"\"\n",
    "    Find the least dense area in the simulation box\n",
    "    Args:\n",
    "        snap: hoomd.Snapshot object\n",
    "        grid_size: size of the grid for histogram\n",
    "    Returns:\n",
    "        tuple: coordinates of the center of the least dense area\n",
    "        float: minimum density value\n",
    "    \"\"\"\n",
    "    # get the positions of the particles\n",
    "    positions = snap.particles.position\n",
    "    box=snap.configuration.box\n",
    "    Lx,Ly,Lz=box[:3]\n",
    "\n",
    "    # create a 3D histogram of the positions\n",
    "    x_bins=np.linspace(-Lx/2,Lx/2,grid_size+1)\n",
    "    y_bins=np.linspace(-Ly/2,Ly/2,grid_size+1)\n",
    "    z_bins=np.linspace(-Lz/2,Lz/2,grid_size+1)\n",
    "\n",
    "    hist,edges=np.histogramdd(positions,bins=(x_bins,y_bins,z_bins))\n",
    "    min_density=np.min(hist)\n",
    "\n",
    "    # find the center of the least dense area\n",
    "    x_min,y_min,z_min=np.unravel_index(np.argmin(hist),hist.shape)\n",
    "    x_center=(x_bins[x_min]+x_bins[x_min+1])/2\n",
    "    y_center=(y_bins[y_min]+y_bins[y_min+1])/2\n",
    "    z_center=(z_bins[z_min]+z_bins[z_min+1])/2\n",
    "\n",
    "    return (x_center,y_center,z_center), min_density\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two points in 3D space.\n",
    "    \n",
    "    Args:\n",
    "        point1 (tuple): The (x, y, z) coordinates of the first point.\n",
    "        point2 (tuple): The (x, y, z) coordinates of the second point.\n",
    "    \n",
    "    Returns:\n",
    "        float: The Euclidean distance between the two points.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((np.array(point1) - np.array(point2)) ** 2))\n",
    "\n",
    "def check_overlaps(polymer_dict):\n",
    "    \"\"\"\n",
    "    Check for overlaps between polymers in the given dictionary.\n",
    "    \n",
    "    Args:\n",
    "        polymer_dict (dict): A dictionary where keys are polymer IDs and values are tuples of x, y, z coordinates.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    overlapping_points = []\n",
    "\n",
    "    # Check for overlapping points or points with distance < 1 between polymers\n",
    "    for polymer_id, (x, y, z) in polymer_dict.items():\n",
    "        points = list(zip(x, y, z))\n",
    "        num_points = len(points)\n",
    "        for i in range(num_points):\n",
    "            for j in range(i + 1, num_points):\n",
    "                if euclidean_distance(points[i], points[j]) < 1:\n",
    "                    overlapping_points.append((polymer_id, points[i], points[j]))\n",
    "\n",
    "    if overlapping_points:\n",
    "        print(\"Overlapping points or points with distance < 1 found:\")\n",
    "        for polymer_id, point1, point2 in overlapping_points:\n",
    "            print(f\"Polymer {polymer_id}: {point1} and {point2}\")\n",
    "    else:\n",
    "        print(\"No overlapping points or points with distance < 1 found.\")\n",
    "\n",
    "\n",
    "def choose_seeds(NP,L,box_length,spacing,current_positions=[],choose=True,seedfill=0):\n",
    "    \"\"\"\n",
    "    Choose seed positions for polymers in the simulation box.\n",
    "    \n",
    "    Args:\n",
    "        NP (int): Number of polymers.\n",
    "        L (int): Length of each polymer.\n",
    "        box_length (float): Length of the simulation box.\n",
    "        spacing (float): Region of replication in simulation box.\n",
    "        current_positions (list): List of current polymer positions.\n",
    "        choose (bool): Whether to choose new seed positions.\n",
    "        seedfill (int): Seed value for random number generator.\n",
    "    \n",
    "    Returns:\n",
    "        int: Seed value for random number generator.\n",
    "        int: Seed value for molecular dynamics.\n",
    "    \"\"\"\n",
    "\n",
    "    if choose:\n",
    "        seed=random.randint(0,2**32-1)\n",
    "        mdseed=random.randint(0,65535)\n",
    "    else:\n",
    "        seed=seedfill\n",
    "\n",
    " \n",
    "    trajdict=multiple_walks(NP,L,box_length,spacing,seed,current_positions)\n",
    "    if trajdict==None:\n",
    "        while trajdict is None:\n",
    "            seed=random.randint(0,2**32-1)\n",
    "            trajdict=multiple_walks(NP,L,box_length,spacing,seed,current_positions)\n",
    "\n",
    "    return seed,mdseed\n",
    "\n",
    "def surrounding_check(x_p,y_p,z_p, b,polymer_check):\n",
    "    \"\"\"\n",
    "    Check if the new position is surrounded by other polymer positions within a distance of 1 unit.\n",
    "    \n",
    "    Args:\n",
    "        x_p (int): x-coordinate of the position to check.\n",
    "        y_p (int): y-coordinate of the position to check.\n",
    "        z_p (int): z-coordinate of the position to check.\n",
    "        b (int): Distance between particles.\n",
    "        polymer_check (set): Set of all polymer positions.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the position is surrounded by other polymer positions, False otherwise.\n",
    "    \"\"\"\n",
    "    possible_moves = [(b, 0, 0), (-b, 0, 0), (0, b, 0), (0, -b, 0), (0, 0, b), (0, 0, -b)]\n",
    "    for move in possible_moves:\n",
    "        new_x = x_p + move[0]\n",
    "        new_y = y_p + move[1]\n",
    "        new_z = z_p + move[2]\n",
    "        #dist= np.sqrt((new_x-x_p)**2+(new_y-y_p)**2+(new_z-z_p)**2)\n",
    "        if (new_x, new_y, new_z) not in polymer_check: # and dist>=1:\n",
    "            # Found a move that is not occupied, so the position is not completely surrounded\n",
    "            return False\n",
    "    # All possible moves are occupied, so the position is completely surrounded\n",
    "    return True\n",
    "\n",
    "\n",
    "def surrounding_current(x_p,y_p,z_p,set_positions):\n",
    "    \"\"\"\n",
    "    Check if the current position is within 1 unit of any existing position.\n",
    "    \n",
    "    Args:\n",
    "        x_p (int): x-coordinate of the current position.\n",
    "        y_p (int): y-coordinate of the current position.\n",
    "        z_p (int): z-coordinate of the current position.\n",
    "        set_positions (set): Set of all existing polymer positions.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the current position is within 1 unit of any existing position, False otherwise.\n",
    "    \"\"\"\n",
    "    for pos in set_positions:\n",
    "        differences=np.linalg.norm(pos-np.array([x_p,y_p,z_p]))\n",
    "        if (x_p,y_p,z_p) in set_positions or differences<1:\n",
    "            # The new position is within 1 unit of an existing position\n",
    "            return True\n",
    "    # There is no existing position within 1 unit of the new position\n",
    "    return False\n",
    "\n",
    "\n",
    "def multiple_walks(NP, L, box_length,spacing,seed, current_positions=[]):  \n",
    "    \"\"\"\n",
    "    Generate multiple random walks for polymers in a simulation box.\n",
    "    \n",
    "    Args:\n",
    "        NP (int): Number of polymers.\n",
    "        L (int): Length of each polymer.\n",
    "        box_length (float): Length of the simulation box.\n",
    "        spacing (float): Region of replication in simulation box.\n",
    "        seed (int): Seed value for random number generator.\n",
    "        current_positions (list): List of current polymer positions.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary where keys are polymer IDs and values are tuples of x, y, z coordinates.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the random seed\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Initialize the polymer dictionary\n",
    "    polymer_dict={}\n",
    "    b=1         \n",
    "    polymer_check=set()  \n",
    "    \n",
    "    # Add the current positions to the set if they exist\n",
    "    set_positions=set()\n",
    "    if len(current_positions)>0:\n",
    "        for x,y,z in current_positions:\n",
    "            set_positions.add((x,y,z))\n",
    "    else:\n",
    "        set_positions=set()\n",
    "    \n",
    "    # Generate the random walk for each polymer\n",
    "    for polymer_id in range(NP):\n",
    "        # Initialize the polymer coordinates\n",
    "        start_box_size=int(box_length/spacing) \n",
    "        x=np.zeros(L)\n",
    "        y=np.zeros(L)\n",
    "        z=np.zeros(L)\n",
    "        fail_starts=set()\n",
    "        start=False\n",
    "\n",
    "        # Choose a random starting position\n",
    "        while not start:\n",
    "            available_starts=[(x,y,z) for x in range(-start_box_size, start_box_size + 1) \n",
    "                            for y in range(-start_box_size ,start_box_size +1)\n",
    "                            for z in range(-start_box_size,start_box_size+1)\n",
    "                            if (x,y,z) not in fail_starts]\n",
    "            \n",
    "            start_position=available_starts[np.random.randint(len(available_starts))]\n",
    "            x[0],y[0],z[0]=start_position\n",
    "\n",
    "            # Check if the starting position is valid\n",
    "            if (x[0],y[0],z[0]) not in polymer_check and not surrounding_current(x[0],y[0],z[0],set_positions):\n",
    "                polymer_check.add((x[0],y[0],z[0]))\n",
    "                start=True\n",
    "            else:\n",
    "                fail_starts.add(start_position)\n",
    "    \n",
    "        # Generate the random walk for the polymer\n",
    "        possible_steps=[(b,0,0),(-b,0,0),(0,b,0),(0,-b,0),(0,0,b),(0,0,-b)] #5,1,0,3 \n",
    "        for i in range(1, L):\n",
    "            failed_steps=set()\n",
    "            step_taken = False\n",
    "            # Try to take a step until a valid step is taken\n",
    "            while not step_taken:\n",
    "                new_x, new_y, new_z = x[i - 1], y[i - 1], z[i - 1]\n",
    "                available_steps=[step for step in possible_steps if step not in failed_steps] #this index is changing as fail steps occur\n",
    "                # Randomly generate the step directions\n",
    "                if len(available_steps)==0:\n",
    "                    return None\n",
    "                step_index=np.random.randint(len(available_steps))\n",
    "                move=available_steps[step_index]\n",
    "                # Calculate potential new position\n",
    "                new_x += move[0]\n",
    "                new_y += move[1]\n",
    "                new_z += move[2]\n",
    "                # Check if the new position is already occupied\n",
    "                if ((new_x, new_y, new_z) not in polymer_check and\n",
    "                    not surrounding_current(new_x, new_y, new_z, set_positions) and\n",
    "                    not surrounding_check(new_x, new_y, new_z, b, polymer_check) and\n",
    "                    np.abs(new_x) < box_length / 2 and\n",
    "                    np.abs(new_y) < box_length / 2 and\n",
    "                    np.abs(new_z) < box_length / 2):\n",
    "                    x[i], y[i], z[i] = new_x, new_y, new_z\n",
    "                    polymer_check.add((new_x, new_y, new_z))\n",
    "                    step_taken=True \n",
    "                else: \n",
    "                    failed_steps.add(move)\n",
    "        # Add the polymer to the dictionary\n",
    "        polymer_dict[polymer_id]=(x,y,z)\n",
    "    return polymer_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddPolymer(hoomd.custom.Action):\n",
    "    \"\"\"Add a polymer to the simulation box\n",
    "    \n",
    "    Args:\n",
    "        sim (hoomd.Simulation): The simulation object.\n",
    "        L (int): The length of the polymer.\n",
    "        LE (int): The number of monomers of type E.\n",
    "        LM (int): The number of monomers of type M.\n",
    "        box_length (float): The length of the simulation box.\n",
    "        spacing (float): Region of replication in simulation box.\n",
    "        seed (int): The seed for the random number generator.\n",
    "        monomer_types (list): The list of monomer types.\n",
    "        countcheck (int): The number of polymers to check for before adding more.\n",
    "    \"\"\"\n",
    "    def __init__(self, sim, L, LE,LM,box_length,spacing,seed,monomer_types=['A','B','C'],countcheck=50):\n",
    "        super().__init__()\n",
    "        self.sim = sim\n",
    "        self.L = L\n",
    "        self.LE = LE\n",
    "        self.LM = LM\n",
    "        self.box_length = box_length\n",
    "        self.spacing = spacing\n",
    "        self.seed = seed\n",
    "        self.monomer_types = monomer_types\n",
    "        self.countcheck=countcheck\n",
    "\n",
    "    def act(self, timestep):\n",
    "        L = self.L\n",
    "        snapshot=self.sim.state.get_snapshot()\n",
    "        if self.sim.device.communicator.rank == 0:\n",
    "            # Add new particles to the snapshot\n",
    "            N = self.L\n",
    "            new_snapshot = snapshot\n",
    "            current_pos = snapshot.particles.position\n",
    "            num_poly=len(current_pos)/N\n",
    "\n",
    "            # Check if the number of polymers is less than the countcheck\n",
    "            if num_poly < self.countcheck:\n",
    "                seed,mdseed = choose_seeds(1, L, self.box_length,self.spacing, current_positions=current_pos, choose=True, seedfill=self.seed)\n",
    "                polymer_dict = multiple_walks(1, L, self.box_length,self.spacing,seed, current_positions=current_pos)\n",
    "                new_snapshot.particles.N += N\n",
    "                positions=[]\n",
    "\n",
    "                # Add the new polymer to the snapshot\n",
    "                for polymer in polymer_dict:\n",
    "                    x,y,z=polymer_dict[polymer]\n",
    "                    positions.extend([(xi,yi,zi) for xi,yi,zi in zip(x,y,z)])\n",
    "                new_snapshot.particles.position[-N:] = positions\n",
    "                new_snapshot.particles.velocity[-N:] = np.random.normal(0, 1, (N, 3))\n",
    "                new_snapshot.particles.typeid[-N:] = [1]*self.LE + [0]*self.LM + [2]*self.LE\n",
    "                new_snapshot.particles.mass[-N:] = 1.0  \n",
    "                new_snapshot.particles.diameter[-N:] = 1.0\n",
    "                new_snapshot.bonds.N += (L - 1)\n",
    "                new_snapshot.bonds.types = ['A-A']\n",
    "                new_snapshot.bonds.typeid[-(L-1):]=[0]*(L-1)\n",
    "                bond_groups = []\n",
    "                start_index = new_snapshot.particles.N - N\n",
    "                \n",
    "                # Add bonds between the particles in the polymer\n",
    "                for i in range(start_index, start_index + L - 1):\n",
    "                    bond_groups.append([i, i + 1])\n",
    "                new_snapshot.bonds.group[-(L-1):] = bond_groups\n",
    "                harmonic = hoomd.md.bond.Harmonic()\n",
    "                harmonic.params['A-A']=dict(k=100,r0=1.0)\n",
    "                \n",
    "                # Define the Lennard-Jones potential\n",
    "                #lennard jones\n",
    "                #RNA-RNA\n",
    "                lj = hoomd.md.pair.LJ(nlist=hoomd.md.nlist.Cell(buffer=0.4),default_r_cut=2.5,mode='shift')\n",
    "                lj.params[('A','A')] = dict(epsilon=3,sigma=1)\n",
    "                lj.params[('B','B')] = dict(epsilon=0.1,sigma=1)\n",
    "                lj.params[('C','C')] = dict(epsilon=0.1,sigma=1)\n",
    "                lj.params[('A','B')] = dict(epsilon=0.1,sigma=1)\n",
    "                lj.params[('A','C')] = dict(epsilon=0.1,sigma=1)\n",
    "                lj.params[('B','C')] = dict(epsilon=0.1,sigma=1)\n",
    "                force=[harmonic,lj]\n",
    "\n",
    "\n",
    "                # Set the forces\n",
    "                self.sim.operations.integrator.forces = force\n",
    "                # Set the new snapshot with bonds as the current state\n",
    "                self.sim.state.set_snapshot(new_snapshot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running simulations functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make initial frame\n",
    "def createframe(N,L,LE,LM,box_size,spacing,IS_file):\n",
    "    \"\"\"Create the initial frame for the simulation\n",
    "\n",
    "    Args:\n",
    "        N (int): Number of polymers.\n",
    "        L (int): Length of each polymer (ie. number of monomers).\n",
    "        LE (int): Number of monomers of type 3'/5'.\n",
    "        LM (int): Number of monomers of type M.\n",
    "        box_size (float): Size of the simulation box.\n",
    "        spacing (float): SRegion of replication in simulation box.\n",
    "        IS_file (str): Initial snapshot file name.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Seeds for the polymer and molecular dynamics.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Choose seeds for the polymer\n",
    "    seeds,mdseed=choose_seeds(N,L,box_size,spacing,current_positions=[])\n",
    "    # Generate the polymer dictionary\n",
    "    polymer_dict = multiple_walks(N,L,box_size,spacing,seeds,current_positions=[])\n",
    "    #Create the initial frame\n",
    "    frame=gsd.hoomd.Frame()\n",
    "    frame.particles.N=L\n",
    "    positions=[]\n",
    "    for polymer_id in polymer_dict:\n",
    "        x,y,z=polymer_dict[polymer_id]\n",
    "        positions.extend([(xi,yi,zi) for xi,yi,zi in zip(x,y,z)])\n",
    "    frame.particles.position=positions\n",
    "    frame.particles.types=['A','B','C']\n",
    "    # Define bonds\n",
    "    frame.bonds.N = (L - 1) * N\n",
    "    frame.bonds.types = ['A-A']\n",
    "    frame.bonds.typeid = [0] * frame.bonds.N\n",
    "    bond_groups = []\n",
    "    for n in range(N):\n",
    "        start_index = n * L\n",
    "        for i in range(start_index, start_index + L - 1):\n",
    "            bond_groups.append([i, i + 1])\n",
    "    frame.bonds.group = bond_groups\n",
    "\n",
    "    #Define particle types\n",
    "    frame.particles.typeid=[1]*LE+[0]*LM+[2]*LE\n",
    "    frame.particles.mass=np.array([1.0]*L)\n",
    "    frame.particles.diameter=np.array([1.0]*L)\n",
    "    frame.configuration.box=np.array([box_size,box_size,box_size,0,0,0])\n",
    "\n",
    "    with gsd.hoomd.open(IS_file, 'w') as f:\n",
    "        f.append(frame)\n",
    "\n",
    "    return seeds,mdseed\n",
    "\n",
    "\n",
    " \n",
    "def add_forces(trig,Mep,Eep,EMep,seeds,mdseed,IS_file,LE,LM,L,box_size,spacing,run):\n",
    "        \"\"\"Add forces to the simulation\n",
    "\n",
    "        Args:\n",
    "            trig (int): Trigger period for adding polymers.\n",
    "            Mep (float): Lennard-Jones epsilon parameter for middle monomer interactions.\n",
    "            Eep (float): Lennard-Jones epsilon parameter for 5'/3' monomer interactions.\n",
    "            EMep (float): Lennard-Jones epsilon parameter for 5'/3'-middle monomer interactions.\n",
    "            seeds (list): Seeds for the polymer.\n",
    "            mdseed (int): Seed for the molecular dynamics.\n",
    "            IS_file (str): Initial frame file.\n",
    "            LE (int): Number of monomers of type 3'/5'.\n",
    "            LM (int): Number of monomers of type M.\n",
    "            L (int): Length of each polymer (ie. number of monomers).\n",
    "            box_size (float): Size of the simulation box.\n",
    "            spacing (float): Region of replication in simulation box.\n",
    "            run (int): Run number for the simulation.\n",
    "        \"\"\"\n",
    "\n",
    "        #harmonic bond\n",
    "        harmonic = hoomd.md.bond.Harmonic()\n",
    "        harmonic.params['A-A']=dict(k=100,r0=1.05)\n",
    "\n",
    "        #lennard jones\n",
    "        #RNA-RNA\n",
    "        lj = hoomd.md.pair.LJ(nlist=hoomd.md.nlist.Cell(buffer=0.4),default_r_cut=2.5,mode='shift')\n",
    "        lj.params[('A','A')] = dict(epsilon=Mep,sigma=1)\n",
    "        lj.params[('B','B')] = dict(epsilon=Eep,sigma=1)\n",
    "        lj.params[('C','C')] = dict(epsilon=Eep,sigma=1)\n",
    "        lj.params[('A','B')] = dict(epsilon=EMep,sigma=1)\n",
    "        lj.params[('A','C')] = dict(epsilon=EMep,sigma=1)\n",
    "        lj.params[('B','C')] = dict(epsilon=EMep,sigma=1)\n",
    "        force=[harmonic,lj]\n",
    "\n",
    "        #initialize simulation\n",
    "        device=hoomd.device.CPU()\n",
    "        sim=hoomd.Simulation(device=device,seed=mdseed)\n",
    "        sim.create_state_from_gsd(filename=IS_file)\n",
    "        langevin = hoomd.md.methods.Langevin(filter=hoomd.filter.All(),kT=1.0)\n",
    "        integrator=hoomd.md.Integrator(dt=1e-2,methods=[langevin],forces=force)\n",
    "        sim.operations.integrator=integrator\n",
    "\n",
    "        #use AddPolymer class to add polymers over steps\n",
    "        add_polymer=AddPolymer(sim, L, LE, LM, box_size, spacing, seeds)\n",
    "        trigger=hoomd.trigger.Periodic(int(trig))\n",
    "        custom_op=hoomd.update.CustomUpdater(trigger=trigger,action=add_polymer)\n",
    "        sim.operations.updaters.append(custom_op)\n",
    "\n",
    "        #add logger\n",
    "        thermo=hoomd.md.compute.ThermodynamicQuantities(filter=hoomd.filter.All())\n",
    "        sim.operations.computes.append(thermo)\n",
    "        logger=hoomd.logging.Logger()\n",
    "        logger.add(sim,quantities=['timestep','tps','walltime'])\n",
    "        logger.add(thermo)\n",
    "\n",
    "        #make trajectory file\n",
    "        name=f'Trajectory_trigger_{trig}_sp_{spacing}_Mep_3_Ep01_limit50_run_{run}.gsd'\n",
    "        path=os.path.dirname('Trajectories/Limit50_L45/')\n",
    "        os.makedirs(path,exist_ok=True)\n",
    "        outpath=os.path.join(path,name)\n",
    "\n",
    "        #log gsd\n",
    "        gsd_writer=hoomd.write.GSD(trigger=hoomd.trigger.Periodic(100), ##ENTER PERIOD LOGGING FOR SIMULATION\n",
    "                filename=outpath,\n",
    "                filter=hoomd.filter.All(),\n",
    "                mode='wb',\n",
    "                logger=logger)\n",
    "\n",
    "        sim.operations.writers.append(gsd_writer)\n",
    "        sim.run(5e4) ## ENTER TIME FOR SIMULATION\n",
    "        gsd_writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CumulativeAverage:\n",
    "    \"\"\"\n",
    "    A class to calculate the cumulative average of a list, numpy array, or dictionary of values.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the CumulativeAverage class.\n",
    "        \"\"\"\n",
    "        self.numbers = []\n",
    "        self.dict={}\n",
    "        self.current_average = None\n",
    "        self.cumulative_averages = []\n",
    "\n",
    "    def add_value(self, new_value):\n",
    "        \"\"\"Adding new data to list\"\"\"\n",
    "\n",
    "        #If new value is a float\n",
    "        if isinstance(new_value, (int,float)):\n",
    "            self.numbers.append(new_value)\n",
    "            sum_list=0\n",
    "            if self.current_average is None:\n",
    "                self.current_average = new_value\n",
    "            else:\n",
    "                for i in range(len(self.numbers)):\n",
    "                    sum_list+=self.numbers[i]\n",
    "                self.current_average = sum_list/(len(self.numbers))\n",
    "        \n",
    "        #If new value is an array\n",
    "        elif isinstance(new_value, (list,np.ndarray)):\n",
    "            new_value=np.array(new_value)\n",
    "            self.numbers.append(new_value)\n",
    "            if self.current_average is None:\n",
    "                self.current_average = new_value\n",
    "            else:\n",
    "                sum_list=0\n",
    "                for i in range(len(self.numbers)):\n",
    "                    sum_list+=self.numbers[i]\n",
    "                self.current_average = sum_list/(len(self.numbers))\n",
    "\n",
    "        #If new value is a dictionary\n",
    "        elif isinstance(new_value, dict):\n",
    "            for key, value in new_value.items():\n",
    "                if key not in self.numbers:\n",
    "                    self.dict[key] = []\n",
    "                self.dict[key].append(value)\n",
    "                if self.current_average is None:\n",
    "                    self.current_average = {key: value}\n",
    "                else:\n",
    "                    sum_list=0\n",
    "                    for i in range(len(self.dict[key])):\n",
    "                        sum_list+=self.dict[key][i]\n",
    "                    self.current_average[key] = sum_list/(len(self.dict[key]))\n",
    "        self.cumulative_averages.append(self.current_average)\n",
    "        return self.current_average\n",
    "    \n",
    "    #return cumulative average\n",
    "    def get_cumulative_averages(self):\n",
    "        \"\"\"\n",
    "        Get the cumulative averages.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of cumulative averages.\n",
    "        \"\"\"\n",
    "        return self.cumulative_averages\n",
    "    \n",
    "\n",
    "\n",
    "class DataAverager:\n",
    "    \"\"\"\n",
    "    A class to average data from multiple dictionaries.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the DataAverager class.\n",
    "        \"\"\"\n",
    "        self.data = {}\n",
    "        self.file_count = {}\n",
    "\n",
    "    def add_data(self, dictionary):\n",
    "        \"\"\"\n",
    "        Add data from a dictionary to the DataAverager.\n",
    "\n",
    "        Args:\n",
    "            dictionary (dict): A dictionary where keys are data labels and values are lists or numpy arrays of data points.\n",
    "        \"\"\"\n",
    "        for key,data in dictionary.items():\n",
    "            if key not in self.data:\n",
    "                self.data[key] = np.array(data)\n",
    "                self.file_count[key] = 1\n",
    "            else:\n",
    "                self.data[key] += np.array(data)\n",
    "                self.file_count[key] += 1\n",
    "\n",
    "    def compute_average(self):\n",
    "        \"\"\"\n",
    "        Compute the average of the data.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary where keys are data labels and values are the averaged data points.\n",
    "        \"\"\"\n",
    "        averaged_data = {key: value / self.file_count[key] for key, value in self.data.items()}\n",
    "        return averaged_data\n",
    "\n",
    "def savedata(path,dataname,data):\n",
    "    \"\"\"\n",
    "    Save data to a specified path using pickle.\n",
    "\n",
    "    Args:\n",
    "        path (str): The directory path where the data will be saved.\n",
    "        dataname (str): The name of the file to save the data as.\n",
    "        data (any): The data to be saved.\n",
    "    \"\"\"\n",
    "    DA_path=path+dataname\n",
    "    os.makedirs(os.path.dirname(DA_path), exist_ok=True)\n",
    "    with open(DA_path, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def cluster(gsd_file,L=45):\n",
    "    \"\"\"\n",
    "    Analyze clusters in a GSD file.\n",
    "\n",
    "    Args:\n",
    "        gsd_file (str): The path to the GSD file to analyze.\n",
    "        L (int, optional): The length of the polymers. Defaults to 45.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the number of polymers, number of clusters, cluster mass, and time.\n",
    "    \"\"\"\n",
    "    #Initialize properties to average and to append\n",
    "    data={}\n",
    "    num_clusters=CumulativeAverage()\n",
    "    num_p=[]\n",
    "    clustermass=CumulativeAverage()\n",
    "    time=[]\n",
    "\n",
    "    #Run through each frame\n",
    "    with gsd.hoomd.open(gsd_file, 'r') as traj:\n",
    "        for n,frame in enumerate(traj):\n",
    "            \n",
    "            positions = frame.particles.position\n",
    "            box=frame.configuration.box\n",
    "\n",
    "            #determine clusters and cluster properties\n",
    "            cp= freud.cluster.Cluster()\n",
    "            system=freud.AABBQuery(box,positions)\n",
    "            cp.compute(system,neighbors={'r_max':2})  \n",
    "            clp=freud.cluster.ClusterProperties()\n",
    "            clp.compute(system,cp.cluster_idx)\n",
    "\n",
    "            #store data to cumulative average\n",
    "            num_particles = len(positions)\n",
    "            num_polymers=num_particles//L\n",
    "            num_p.append(num_polymers)\n",
    "            num_clusters.add_value(float(cp.cluster_idx.max()))\n",
    "            clustermass.add_value(np.max(clp.sizes)/L)\n",
    "            time.append(frame.configuration.step)\n",
    "        \n",
    "        #get cumulative averages\n",
    "        number_clust=num_clusters.get_cumulative_averages()\n",
    "        number_mass=clustermass.get_cumulative_averages()\n",
    "        data['num_polymers']=num_p\n",
    "        data['num_clusters']=number_clust\n",
    "        data['cluster_mass']=number_mass\n",
    "        data['time']=time\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_simulation_snapshot(gsd_file,num_frames=1,L=45):\n",
    "    \"\"\"\n",
    "    Render the last few frames of a simulation from a GSD file.\n",
    "\n",
    "    Args:\n",
    "        gsd_file (str): Path to the GSD file containing the simulation data.\n",
    "        num_frames (int): Number of frames to render from the end of the simulation. Default is 1.\n",
    "        L (int): Length of each polymer. Default is 45.\n",
    "    \"\"\"\n",
    "    # Open the GSD file\n",
    "    with gsd.hoomd.open(gsd_file, 'r') as traj:\n",
    "        # Read the last frame\n",
    "        for n,frame in enumerate(traj[-num_frames:]):\n",
    "        \n",
    "            # Extract particle positions\n",
    "            box_size=frame.configuration.box[0]\n",
    "            positions = frame.particles.position\n",
    "            num_particles = len(positions)  \n",
    "            num_polymer = num_particles//L\n",
    "            \n",
    "\n",
    "            # Create a color array\n",
    "            colors = np.zeros(num_particles, dtype=int)\n",
    "            for i in range(num_polymer):\n",
    "                colors[i*L:(i+1)*L] = i\n",
    "            \n",
    "            # Create a colormap\n",
    "            cmap = plt.get_cmap('viridis', num_polymer)\n",
    "            # Create a 3D scatter plot of the particle positions\n",
    "            fig = plt.figure(figsize=(8, 8))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            scatter = ax.scatter(positions[:, 0], positions[:, 1], positions[:, 2], c=colors, cmap=cmap, s=1)\n",
    "            #ax.plot(positions[:, 0], positions[:, 1], positions[:, 2], 'k-', alpha=0.1)\n",
    "            ax.set_xlim(-box_size/2, box_size/2)\n",
    "            ax.set_ylim(-box_size/2, box_size/2)\n",
    "            ax.set_zlim(-box_size/2, box_size/2)\n",
    "            ax.set_xlabel('X Position')\n",
    "            ax.set_ylabel('Y Position')\n",
    "            ax.set_zlabel('Z Position')\n",
    "            ax.set_title(f'Simulation Snapshot at Frame {n}')\n",
    "            \n",
    "            # Add a color bar\n",
    "            cbar = plt.colorbar(scatter, ax=ax, ticks=range(num_polymer))\n",
    "            cbar.set_label('Segment Index')\n",
    "            plt.show()\n",
    "\n",
    "def plot_across(fileset,outputfolder,save=False):\n",
    "    \"\"\"Plot the number of clusters, number of polymers, and average cluster size across different subregions sizes and trigger rates\n",
    "    Args:\n",
    "    - fileset: dictionary of files\n",
    "    - outputfolder: list of output files\n",
    "    - save: boolean to save the plots\n",
    "    \"\"\"\n",
    "    \n",
    "    i=0\n",
    "    color=['#1b9e77','#d95f02','#7570b3','#e7298a','#66a61e','#e6ab02','#a6761d','#666666'] #set of colors\n",
    "\n",
    "    #loop through each average set of data\n",
    "    for name,file in fileset.items():\n",
    "        #load data\n",
    "        data=pickle.load(open(file,'rb'))\n",
    "        time=data['time']\n",
    "        number_clust=data['num_clusters']\n",
    "        number_mass=data['cluster_mass']\n",
    "        num_polymers=data['num_polymers']  \n",
    "\n",
    "        #plot number of clusters in simulation\n",
    "        plt.figure(1)\n",
    "        plt.plot(time,number_clust,label=name,color=color[i])\n",
    "        plt.xlabel('Simulation Time')\n",
    "        plt.ylabel('Number of Clusters')\n",
    "        plt.legend(loc=0)\n",
    "        plt.title(f'Number of Clusters')\n",
    "        if save:\n",
    "            plt.savefig(outputfolder+'Number_of_Clusters.png',bbox_inches='tight',dpi=600)\n",
    "\n",
    "        #plot average number of polymers in largest clusters\n",
    "        plt.figure(2)\n",
    "        plt.plot(time,number_mass,label=name,color=color[i])\n",
    "        plt.xlabel('Simulation Time')\n",
    "        plt.ylabel('Number of Polymer Chains')\n",
    "        plt.title(f'Number of Polymer Chains per Largest Cluster')\n",
    "        plt.legend(loc=0)\n",
    "        if save:\n",
    "            plt.savefig(outputfolder+'PolymerChains_in_LargestClusters.png',bbox_inches='tight',dpi=600)\n",
    "\n",
    "        #plot total number of polymers in simulation\n",
    "        plt.figure(3)\n",
    "        plt.plot(time,num_polymers,label=name,color=color[i])\n",
    "        plt.xlabel('Simulation Time')\n",
    "        plt.ylabel('Number of Polymer Chains')\n",
    "        plt.title(f'Number of Polymer Chains in Simulation')\n",
    "        plt.legend(loc=0)\n",
    "        i+=1\n",
    "        if save:\n",
    "            plt.savefig(outputfolder+'TotalNumber_of_Polymers.png',bbox_inches='tight',dpi=600)\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "N=1 #number of polymers (at beginning)\n",
    "L=45 #length of polymer\n",
    "LM=15 #number of monomers of type M\n",
    "LE=15 #number of monomers of type E\n",
    "box_size=150 #size of the box\n",
    "spacing=[24,2] #subregion of box\n",
    "Mep=3 #epsilon for A-A interaction\n",
    "Eep=0.1 #epsilon for B-B and C-C interaction\n",
    "EMep=0.1 #epsilon for A-B, A-C, and B-C interaction\n",
    "runs=1 #number of runs\n",
    "trig=[100,800] #trigger for adding polymers\n",
    "\n",
    "\n",
    "#loop and run\n",
    "for sp, tr in zip(spacing,trig):\n",
    "        IS_file=f'Initial_Polymer_{sp}_L_{L}.gsd' #Making initial trajectory file for certain groups\n",
    "        for run in range(runs):\n",
    "            seeds,mdseed=createframe(N,L,LE,LM,box_size,sp,IS_file)\n",
    "            add_forces(tr,Mep,Eep,EMep,seeds,mdseed,IS_file,LE,LM,L,box_size,sp,run)\n",
    "            print(f'Run {run} completed with spacing {sp} and trigger {tr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analyze trajectories and average over replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define folder for trajectories\n",
    "folder='Trajectories/Limit50_L45/'\n",
    "\n",
    "#Define folder to store analyzed data\n",
    "Output=f'Outputs/{today}/PolymerLength_45_largestcluster/'\n",
    "\n",
    "\n",
    "#Loop through files, analyze, average\n",
    "for sp,tr in zip(spacing,trig):\n",
    "    #file name \n",
    "    filecheck=f'Trajectory_trigger_{tr}_sp_{sp}_Mep_3_Ep01_limit50'\n",
    "\n",
    "    #initialize average\n",
    "    filedata={}\n",
    "    dataavg=DataAverager() \n",
    "\n",
    "    #average data\n",
    "    for file in os.listdir(folder): \n",
    "        if file.endswith('.gsd') and filecheck in file:\n",
    "            data=cluster(folder+file,L=45)\n",
    "            filedata[file]=data\n",
    "            dataavg.add_data(filedata[file])\n",
    "    averagedata=dataavg.compute_average()\n",
    "    #save data\n",
    "    savedata(Output,filecheck,averagedata)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot renders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through each trajectory and plot\n",
    "for file in os.listdir(folder):\n",
    "    print(file)\n",
    "    render_simulation_snapshot(folder+file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull output folder of analyzed data\n",
    "outputfolder=f'Outputs/{today}/PolymerLength_45_largestcluster/'\n",
    "#Create a figures folder\n",
    "figurefolder=f'Figures/{today}/PolymerLength_45_largestcluster/'\n",
    "os.makedirs(figurefolder,exist_ok=True)\n",
    "\n",
    "#loop throiugh files in loop and store data\n",
    "files=[]\n",
    "for file in os.listdir(outputfolder):\n",
    "    files.append(outputfolder+file)\n",
    "files.sort()\n",
    "\n",
    "#create a dictionary describing features of each trajectory then plot\n",
    "fileset={'Transcription Faster than Diffusion':files[0],'Transcription Slower than Diffusion':files[1]}\n",
    "plot_across(fileset,figurefolder,save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "md",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
